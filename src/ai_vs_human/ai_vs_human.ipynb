{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI vs Human Content Detection\n",
    "\n",
    "Este notebook implementa m√∫ltiples modelos de ML para detectar si un texto fue generado por IA o escrito por humanos.\n",
    "\n",
    "## Estrategia:\n",
    "1. **Baseline r√°pido:** Logistic Regression\n",
    "2. **Modelo principal:** XGBoost con GridSearch\n",
    "3. **Comparaci√≥n:** Random Forest\n",
    "4. **Deep Learning:** PyTorch Neural Network\n",
    "5. **Ensemble:** Combinaci√≥n de los mejores modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, classification_report, roc_auc_score, roc_curve\n)\nimport xgboost as xgb\n\n# PyTorch imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configuraci√≥n\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\nRANDOM_STATE = 42\n\n# Detectar si hay GPU disponible\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'üéÆ PyTorch usando: {device}')\nif torch.cuda.is_available():\n    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n    print(f'   Memoria disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n\n# Detectar si XGBoost puede usar GPU\nuse_gpu_xgb = torch.cuda.is_available()\nif use_gpu_xgb:\n    print(f'üöÄ XGBoost usar√° GPU (tree_method=gpu_hist)')\nelse:\n    print(f'üíª XGBoost usar√° CPU (tree_method=hist)')"
  },
  {
   "cell_type": "markdown",
   "source": "### üéÆ Resumen de Aceleraci√≥n GPU\n\nEste notebook est√° optimizado para usar GPU cuando est√© disponible:\n\n| Modelo | GPU Support | Aceleraci√≥n |\n|--------|-------------|-------------|\n| **Logistic Regression** | ‚ùå No | CPU only (scikit-learn) |\n| **XGBoost** | ‚úÖ S√≠ | `tree_method='gpu_hist'` |\n| **Random Forest** | ‚ùå No | CPU only (scikit-learn) |\n| **PyTorch NN** | ‚úÖ S√≠ | `.to(device)` autom√°tico |\n| **Ensemble** | ‚ö†Ô∏è Parcial | Usa GPU en XGBoost |\n\n**Beneficios de GPU:**\n- XGBoost: 5-10x m√°s r√°pido con GPU\n- PyTorch: 10-50x m√°s r√°pido con GPU (depende del tama√±o del modelo)\n\n**Si no tienes GPU:** El notebook funcionar√° perfectamente en CPU.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploraci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv('ai_human_content_detection_dataset.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumnas: {df.columns.tolist()}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n del dataset\n",
    "print(\"Informaci√≥n del dataset:\")\n",
    "print(df.info())\n",
    "print(\"\\nEstad√≠sticas descriptivas:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de labels\n",
    "print(\"Distribuci√≥n de labels:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nPorcentaje AI (1): {df['label'].mean()*100:.2f}%\")\n",
    "print(f\"Porcentaje Human (0): {(1-df['label'].mean())*100:.2f}%\")\n",
    "\n",
    "# Visualizaci√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "df['label'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Distribuci√≥n de Labels')\n",
    "axes[0].set_xlabel('Label (0=Human, 1=AI)')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_xticklabels(['Human', 'AI'], rotation=0)\n",
    "\n",
    "df['content_type'].value_counts().plot(kind='barh', ax=axes[1])\n",
    "axes[1].set_title('Distribuci√≥n de Tipos de Contenido')\n",
    "axes[1].set_xlabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores faltantes\n",
    "print(\"Valores faltantes por columna:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percentage': missing_pct})\n",
    "print(missing_df[missing_df['Missing'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo features num√©ricas (excluir text_content y content_type)\n",
    "feature_columns = [\n",
    "    'word_count', 'character_count', 'sentence_count', 'lexical_diversity',\n",
    "    'avg_sentence_length', 'avg_word_length', 'punctuation_ratio',\n",
    "    'flesch_reading_ease', 'gunning_fog_index', 'grammar_errors',\n",
    "    'passive_voice_ratio', 'predictability_score', 'burstiness', 'sentiment_score'\n",
    "]\n",
    "\n",
    "# Verificar qu√© columnas existen realmente\n",
    "available_features = [col for col in feature_columns if col in df.columns]\n",
    "print(f\"Features disponibles: {len(available_features)}/{len(feature_columns)}\")\n",
    "print(available_features)\n",
    "\n",
    "# Preparar X e y\n",
    "X = df[available_features].copy()\n",
    "y = df['label'].copy()\n",
    "\n",
    "# Manejar valores faltantes (rellenar con mediana)\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"\\nShape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")\n",
    "print(f\"\\nValores faltantes restantes en X: {X.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nDistribuci√≥n en train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribuci√≥n en test: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar features (importante para Logistic Regression y PyTorch)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features escaladas correctamente\")\n",
    "print(f\"Media train (debe ser ~0): {X_train_scaled.mean(axis=0)[:3]}\")\n",
    "print(f\"Std train (debe ser ~1): {X_train_scaled.std(axis=0)[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"MODELO 1: LOGISTIC REGRESSION (BASELINE)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Entrenar modelo\n",
    "lr_model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Human', 'AI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance para Logistic Regression\n",
    "lr_importance = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'coefficient': lr_model.coef_[0]\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(lr_importance['feature'], lr_importance['coefficient'])\n",
    "plt.xlabel('Coefficient')\n",
    "plt.title('Logistic Regression - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 features m√°s importantes:\")\n",
    "print(lr_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XGBoost con GridSearch (Modelo Principal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 50)\nprint(\"MODELO 2: XGBOOST CON GRIDSEARCH (GPU OPTIMIZADO)\")\nprint(\"=\" * 50)\n\n# Definir grid de hiperpar√°metros\nparam_grid = {\n    'max_depth': [3, 5, 7],\n    'learning_rate': [0.01, 0.1, 0.3],\n    'n_estimators': [100, 200],\n    'subsample': [0.8, 1.0],\n    'colsample_bytree': [0.8, 1.0]\n}\n\n# Modelo base con GPU si est√° disponible (XGBoost 3.1+ usa 'device' en lugar de 'gpu_id')\nif use_gpu_xgb:\n    xgb_base = xgb.XGBClassifier(\n        random_state=RANDOM_STATE,\n        eval_metric='logloss',\n        tree_method='hist',  # 'hist' funciona tanto en CPU como GPU\n        device='cuda:0'  # Especifica GPU (XGBoost 3.1+)\n    )\n    print(\"‚úÖ XGBoost configurado para usar GPU (device='cuda:0')\")\nelse:\n    xgb_base = xgb.XGBClassifier(\n        random_state=RANDOM_STATE,\n        eval_metric='logloss',\n        tree_method='hist',  # CPU optimizado\n        device='cpu'\n    )\n    print(\"‚ÑπÔ∏è XGBoost usando CPU (GPU no disponible)\")\n\n# GridSearch\nprint(\"\\nIniciando GridSearch (esto puede tomar varios minutos)...\")\ngrid_search = GridSearchCV(\n    xgb_base,\n    param_grid,\n    cv=3,\n    scoring='f1',\n    n_jobs=-1,\n    verbose=1\n)\n\ngrid_search.fit(X_train, y_train)\n\nprint(f\"\\n‚úÖ GridSearch completado!\")\nprint(f\"Mejores par√°metros: {grid_search.best_params_}\")\nprint(f\"Mejor F1-score en CV: {grid_search.best_score_:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo de XGBoost\n",
    "xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "print(f\"\\nXGBoost Test Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_xgb):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=['Human', 'AI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance de XGBoost\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(xgb_importance['feature'], xgb_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('XGBoost - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 features m√°s importantes:\")\n",
    "print(xgb_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest (Comparaci√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"MODELO 3: RANDOM FOREST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Entrenar Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "print(f\"\\nRandom Forest Test Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Human', 'AI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance de Random Forest\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(rf_importance['feature'], rf_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest - Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 features m√°s importantes:\")\n",
    "print(rf_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. PyTorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir arquitectura de la red neuronal\n",
    "class AIDetectorNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AIDetectorNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Inicializar modelo\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "pytorch_model = AIDetectorNN(input_dim).to(device)\n",
    "\n",
    "print(\"Arquitectura del modelo PyTorch:\")\n",
    "print(pytorch_model)\n",
    "print(f\"\\nN√∫mero de par√°metros: {sum(p.numel() for p in pytorch_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 50)\nprint(\"MODELO 4: PYTORCH NEURAL NETWORK (GPU OPTIMIZADO)\")\nprint(\"=\" * 50)\n\n# Preparar datos para PyTorch\nX_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\ny_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\nX_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\ny_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1).to(device)\n\nprint(f\"‚úÖ Datos movidos a {device}\")\nprint(f\"   Train tensor shape: {X_train_tensor.shape}\")\nprint(f\"   Test tensor shape: {X_test_tensor.shape}\")\n\n# Crear DataLoaders con pin_memory para GPU\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=128,  # Batch size mayor para GPU\n    shuffle=True,\n    num_workers=0,  # 0 porque los datos ya est√°n en GPU\n    pin_memory=False  # False porque ya est√°n en GPU\n)\n\n# Definir loss y optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(pytorch_model.parameters(), lr=0.001, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n\n# Entrenamiento\nnum_epochs = 50\ntrain_losses = []\nval_losses = []\n\nprint(\"\\nüöÄ Entrenando modelo PyTorch...\")\nimport time\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    # Training\n    pytorch_model.train()\n    epoch_loss = 0\n    for batch_X, batch_y in train_loader:\n        optimizer.zero_grad()\n        outputs = pytorch_model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    \n    avg_train_loss = epoch_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n    \n    # Validation\n    pytorch_model.eval()\n    with torch.no_grad():\n        val_outputs = pytorch_model(X_test_tensor)\n        val_loss = criterion(val_outputs, y_test_tensor)\n        val_losses.append(val_loss.item())\n    \n    scheduler.step(val_loss)\n    \n    if (epoch + 1) % 10 == 0:\n        elapsed = time.time() - start_time\n        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f} - Tiempo: {elapsed:.1f}s\")\n\ntotal_time = time.time() - start_time\nprint(f\"\\n‚úÖ Entrenamiento completado en {total_time:.2f} segundos!\")\nprint(f\"   Tiempo promedio por epoch: {total_time/num_epochs:.2f}s\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de p√©rdida durante entrenamiento\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('PyTorch Model - Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo PyTorch\n",
    "pytorch_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_proba_pytorch = pytorch_model(X_test_tensor).cpu().numpy()\n",
    "    y_pred_pytorch = (y_pred_proba_pytorch > 0.5).astype(int).flatten()\n",
    "\n",
    "# M√©tricas\n",
    "print(f\"\\nPyTorch Neural Network Test Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_pytorch):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_pytorch):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_pytorch):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_pytorch):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_pytorch):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_pytorch, target_names=['Human', 'AI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"MODELO 5: ENSEMBLE (VOTING CLASSIFIER)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear ensemble con los mejores modelos (sin PyTorch)\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('rf', rf_model)\n",
    "    ],\n",
    "    voting='soft'  # Usar probabilidades\n",
    ")\n",
    "\n",
    "# Entrenar el ensemble con los datos escalados de entrenamiento\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "y_pred_proba_ensemble = ensemble_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "print(f\"\\nEnsemble Test Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_ensemble):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_ensemble):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_ensemble):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_ensemble):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_ensemble):.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_ensemble, target_names=['Human', 'AI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'XGBoost', 'Random Forest', 'PyTorch NN', 'Ensemble'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_lr),\n",
    "        accuracy_score(y_test, y_pred_xgb),\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_pytorch),\n",
    "        accuracy_score(y_test, y_pred_ensemble)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, y_pred_lr),\n",
    "        precision_score(y_test, y_pred_xgb),\n",
    "        precision_score(y_test, y_pred_rf),\n",
    "        precision_score(y_test, y_pred_pytorch),\n",
    "        precision_score(y_test, y_pred_ensemble)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, y_pred_lr),\n",
    "        recall_score(y_test, y_pred_xgb),\n",
    "        recall_score(y_test, y_pred_rf),\n",
    "        recall_score(y_test, y_pred_pytorch),\n",
    "        recall_score(y_test, y_pred_ensemble)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test, y_pred_lr),\n",
    "        f1_score(y_test, y_pred_xgb),\n",
    "        f1_score(y_test, y_pred_rf),\n",
    "        f1_score(y_test, y_pred_pytorch),\n",
    "        f1_score(y_test, y_pred_ensemble)\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        roc_auc_score(y_test, y_pred_proba_lr),\n",
    "        roc_auc_score(y_test, y_pred_proba_xgb),\n",
    "        roc_auc_score(y_test, y_pred_proba_rf),\n",
    "        roc_auc_score(y_test, y_pred_proba_pytorch),\n",
    "        roc_auc_score(y_test, y_pred_proba_ensemble)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Ordenar por F1-Score\n",
    "results = results.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARACI√ìN DE TODOS LOS MODELOS\")\n",
    "print(\"=\" * 80)\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Identificar el mejor modelo\n",
    "best_model_name = results.iloc[0]['Model']\n",
    "best_f1 = results.iloc[0]['F1-Score']\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name} con F1-Score de {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n comparativa\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Gr√°fico 1: M√©tricas por modelo\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "results_melted = results.melt(id_vars='Model', value_vars=metrics_to_plot, \n",
    "                               var_name='Metric', value_name='Score')\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "for model in results['Model']:\n",
    "    model_data = results_melted[results_melted['Model'] == model]\n",
    "    ax1.plot(model_data['Metric'], model_data['Score'], marker='o', label=model)\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Comparaci√≥n de M√©tricas por Modelo')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "min_metric_score = max(0.0, results_melted['Score'].min() - 0.05)\n",
    "ax1.set_ylim([min_metric_score, 1.0])\n",
    "\n",
    "# Gr√°fico 2: F1-Score comparison\n",
    "ax2 = axes[0, 1]\n",
    "colors = ['#4ECDC4' if model == best_model_name else '#FF6B6B' for model in results['Model']]\n",
    "ax2.barh(results['Model'], results['F1-Score'], color=colors)\n",
    "ax2.set_xlabel('F1-Score')\n",
    "ax2.set_title('F1-Score por Modelo')\n",
    "min_f1_score = max(0.0, results['F1-Score'].min() - 0.05)\n",
    "ax2.set_xlim([min_f1_score, 1.0])\n",
    "\n",
    "# Gr√°fico 3: ROC Curves\n",
    "ax3 = axes[1, 0]\n",
    "\n",
    "# ROC para cada modelo\n",
    "models_roc = [\n",
    "    ('Logistic Regression', y_pred_proba_lr),\n",
    "    ('XGBoost', y_pred_proba_xgb),\n",
    "    ('Random Forest', y_pred_proba_rf),\n",
    "    ('PyTorch NN', y_pred_proba_pytorch.flatten()),\n",
    "    ('Ensemble', y_pred_proba_ensemble)\n",
    "]\n",
    "\n",
    "for name, y_proba in models_roc:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    ax3.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})')\n",
    "\n",
    "ax3.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax3.set_xlabel('False Positive Rate')\n",
    "ax3.set_ylabel('True Positive Rate')\n",
    "ax3.set_title('ROC Curves - Todos los Modelos')\n",
    "ax3.legend(loc='lower right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 4: Confusion Matrix del mejor modelo\n",
    "ax4 = axes[1, 1]\n",
    "# Usar XGBoost como ejemplo (generalmente el mejor)\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4,\n",
    "            xticklabels=['Human', 'AI'], yticklabels=['Human', 'AI'])\n",
    "ax4.set_title(f'Confusion Matrix - {best_model_name}')\n",
    "ax4.set_ylabel('True Label')\n",
    "ax4.set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. An√°lisis de Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar errores del mejor modelo (XGBoost)\n",
    "errors_df = X_test.copy()\n",
    "errors_df['true_label'] = y_test.values\n",
    "errors_df['predicted_label'] = y_pred_xgb\n",
    "errors_df['prediction_proba'] = y_pred_proba_xgb\n",
    "errors_df['correct'] = errors_df['true_label'] == errors_df['predicted_label']\n",
    "\n",
    "# False Positives (predijo AI pero era Human)\n",
    "false_positives = errors_df[(errors_df['true_label'] == 0) & (errors_df['predicted_label'] == 1)]\n",
    "print(f\"False Positives (predijo AI, era Human): {len(false_positives)}\")\n",
    "\n",
    "# False Negatives (predijo Human pero era AI)\n",
    "false_negatives = errors_df[(errors_df['true_label'] == 1) & (errors_df['predicted_label'] == 0)]\n",
    "print(f\"False Negatives (predijo Human, era AI): {len(false_negatives)}\")\n",
    "\n",
    "print(f\"\\nTotal de errores: {len(false_positives) + len(false_negatives)}\")\n",
    "print(f\"Total de predicciones correctas: {errors_df['correct'].sum()}\")\n",
    "print(f\"Accuracy: {errors_df['correct'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar caracter√≠sticas de los errores\n",
    "if len(false_positives) > 0:\n",
    "    print(\"\\nCaracter√≠sticas promedio de False Positives (Human clasificado como AI):\")\n",
    "    print(false_positives[available_features].mean())\n",
    "\n",
    "if len(false_negatives) > 0:\n",
    "    print(\"\\nCaracter√≠sticas promedio de False Negatives (AI clasificado como Human):\")\n",
    "    print(false_negatives[available_features].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusiones y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CONCLUSIONES FINALES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n1. Mejor Modelo: {best_model_name}\")\n",
    "print(f\"   - F1-Score: {best_f1:.4f}\")\n",
    "print(f\"   - Accuracy: {results[results['Model'] == best_model_name]['Accuracy'].values[0]:.4f}\")\n",
    "\n",
    "print(f\"\\n2. Features m√°s importantes (XGBoost):\")\n",
    "for idx, row in xgb_importance.head(5).iterrows():\n",
    "    print(f\"   - {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. Comparaci√≥n de enfoques:\")\n",
    "print(f\"   - Modelos tradicionales (LR, XGB, RF): R√°pidos, interpretables, excelente rendimiento\")\n",
    "print(f\"   - PyTorch NN: Comparable pero m√°s complejo y lento de entrenar\")\n",
    "print(f\"   - Ensemble: Combina lo mejor de m√∫ltiples modelos\")\n",
    "\n",
    "print(f\"\\n4. Recomendaci√≥n:\")\n",
    "if best_model_name == 'XGBoost':\n",
    "    print(f\"   ‚úÖ Usar XGBoost para producci√≥n: mejor balance de rendimiento/velocidad\")\n",
    "elif best_model_name == 'Ensemble':\n",
    "    print(f\"   ‚úÖ Usar Ensemble si la latencia no es cr√≠tica: m√°ximo rendimiento\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Usar {best_model_name} seg√∫n tus necesidades espec√≠ficas\")\n",
    "\n",
    "print(f\"\\n5. Pr√≥ximos pasos:\")\n",
    "print(f\"   - Analizar textos espec√≠ficos que causan errores\")\n",
    "print(f\"   - Ajustar threshold de clasificaci√≥n seg√∫n el balance precision/recall deseado\")\n",
    "print(f\"   - Considerar features adicionales si hay disponibles\")\n",
    "print(f\"   - Validar con datos de producci√≥n\")\n",
    "print(f\"   - Guardar el mejor modelo para deployment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}