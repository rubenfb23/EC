{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Reconocimiento de caras de animales\nVoy a seguir el flujo que vimos en clase: preparo las imágenes, saco descriptores HOG, juego con un clustering para ver cómo se reparten y termino con un clasificador en un pipeline completo."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Pasos que me propongo\n1. Listar automáticamente todas las carpetas del dataset para usar todas las imágenes disponibles.\n2. Pasar las fotos a escala de grises, hacerles `resize` y guardarlas aparte.\n3. Guardar un dataset intermedio con joblib (la profe pidió un pickle).\n4. Calcular HOG y mirar un clustering con una gráfica sencilla.\n5. Montar un pipeline con KernelPCA (KPE), hacer GridSearch con validación cruzada, clasificar y sacar una matriz de confusión basada en la validación cruzada."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport random\n\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom PIL import Image, ImageOps, UnidentifiedImageError\n\nfrom skimage.feature import hog\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import KernelPCA\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_predict\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\n\nrandom.seed(42)\nnp.random.seed(42)\n\nplt.style.use('seaborn-v0_8')\nsns.set_theme()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "BASE_DIR = Path('.').resolve()\nDATA_DIR = BASE_DIR / 'AnimalFace' / 'Image'\nPROCESSED_DIR = BASE_DIR / 'AnimalFace' / 'processed_64_gray'\nOUTPUT_DIR = BASE_DIR / 'AnimalFace' / 'outputs'\n\nIMAGE_SIZE = (64, 64)\n\nPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nif not DATA_DIR.exists():\n    raise FileNotFoundError(f'No encontré la carpeta de imágenes en {DATA_DIR}')\n\nCATEGORIES = sorted([p.name for p in DATA_DIR.iterdir() if p.is_dir()])\nprint(f'Trabajo con {len(CATEGORIES)} clases: {CATEGORIES}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Funciones de apoyo\nTodo lo que reutilizo lo meto en helpers sencillos para no repetir código."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from typing import List, Tuple\n\n\ndef collect_image_paths(class_name: str) -> List[Path]:\n    folder = DATA_DIR / class_name\n    supported = []\n    for pattern in ('*.jpg', '*.jpeg', '*.png', '*.bmp'):\n        supported.extend(folder.glob(pattern))\n    return sorted(supported)\n\n\ndef preprocess_image(path: Path, size: Tuple[int, int]) -> np.ndarray:\n    try:\n        with Image.open(path) as image:\n            image = ImageOps.exif_transpose(image)\n            image = ImageOps.grayscale(image)\n            image = image.resize(size, Image.Resampling.LANCZOS)\n            array = np.asarray(image, dtype=np.float32) / 255.0\n    except (UnidentifiedImageError, OSError) as exc:\n        raise ValueError(f'No pude cargar {path}') from exc\n    return array\n\n\ndef save_preprocessed_image(array: np.ndarray, original_path: Path) -> Path:\n    label = original_path.parent.name\n    save_dir = PROCESSED_DIR / label\n    save_dir.mkdir(parents=True, exist_ok=True)\n    save_path = save_dir / f\"{original_path.stem}_64_gray.png\"\n    image_to_save = Image.fromarray((array * 255).astype(np.uint8))\n    image_to_save.save(save_path)\n    return save_path\n\n\ndef build_dataset_descriptor() -> pd.DataFrame:\n    rows = []\n    skipped = 0\n    for label in CATEGORIES:\n        paths = collect_image_paths(label)\n        for path in paths:\n            try:\n                processed = preprocess_image(path, IMAGE_SIZE)\n            except ValueError:\n                print(f\"Salté {path.name} porque PIL no la reconoce bien.\")\n                skipped += 1\n                continue\n            saved_path = save_preprocessed_image(processed, path)\n            rows.append({\n                'label': label,\n                'original_path': path.as_posix(),\n                'processed_path': saved_path.as_posix()\n            })\n    df = pd.DataFrame(rows)\n    df = df.sort_values('label').reset_index(drop=True)\n    if skipped:\n        print(f\"Salté {skipped} imágenes que estaban dañadas o con formato raro.\")\n    return df\n\n\ndef show_before_after(df: pd.DataFrame, samples: int = 4) -> None:\n    subset = df.groupby('label').head(1)\n    subset = subset.sample(min(samples, len(subset)), random_state=42)\n    fig, axes = plt.subplots(len(subset), 2, figsize=(6, 3 * len(subset)))\n    if len(subset) == 1:\n        axes = np.array([axes])\n    for (idx, row), (ax_orig, ax_proc) in zip(subset.iterrows(), axes):\n        orig = Image.open(row['original_path'])\n        proc = Image.open(row['processed_path'])\n        ax_orig.imshow(orig)\n        ax_orig.set_title(f\"{row['label']} original\")\n        ax_orig.axis('off')\n        ax_proc.imshow(proc, cmap='gray')\n        ax_proc.set_title('Preprocesada 64x64 gris')\n        ax_proc.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\ndef hog_from_array(image_array: np.ndarray,\n                   orientations: int = 9,\n                   pixels_per_cell: Tuple[int, int] = (8, 8),\n                   cells_per_block: Tuple[int, int] = (2, 2)) -> np.ndarray:\n    return hog(\n        image_array,\n        orientations=orientations,\n        pixels_per_cell=pixels_per_cell,\n        cells_per_block=cells_per_block,\n        block_norm='L2-Hys',\n        feature_vector=True\n    )\n\n\ndef load_hog_features(df: pd.DataFrame,\n                      orientations: int = 9,\n                      pixels_per_cell: Tuple[int, int] = (8, 8),\n                      cells_per_block: Tuple[int, int] = (2, 2)) -> np.ndarray:\n    features = []\n    for path in df['processed_path']:\n        image = Image.open(path)\n        array = np.asarray(image, dtype=np.float32) / 255.0\n        features.append(hog_from_array(array, orientations, pixels_per_cell, cells_per_block))\n    return np.vstack(features)\n\n\nclass ImageToHog(BaseEstimator, TransformerMixin):\n    def __init__(self, image_size: Tuple[int, int] = IMAGE_SIZE,\n                 orientations: int = 9,\n                 pixels_per_cell: Tuple[int, int] = (8, 8),\n                 cells_per_block: Tuple[int, int] = (2, 2)):\n        self.image_size = image_size\n        self.orientations = orientations\n        self.pixels_per_cell = pixels_per_cell\n        self.cells_per_block = cells_per_block\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        features = []\n        for path in X:\n            array = preprocess_image(Path(path), self.image_size)\n            features.append(hog_from_array(\n                array,\n                orientations=self.orientations,\n                pixels_per_cell=self.pixels_per_cell,\n                cells_per_block=self.cells_per_block\n            ))\n        return np.vstack(features)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Preparo el dataset completo\nAhora recorro todas las carpetas y guardo la versión 64x64 en gris para no tener que regenerarla cada vez."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "dataset_df = build_dataset_descriptor()\nprint(dataset_df.head())\nprint()\nprint(dataset_df['label'].value_counts())\n\nshow_before_after(dataset_df)\n\njoblib.dump(dataset_df, OUTPUT_DIR / 'dataset_descriptor.joblib')\nprint(f\"Descriptor guardado en {OUTPUT_DIR / 'dataset_descriptor.joblib'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### HOG + KPE (KernelPCA) + clustering\nUso KernelPCA como la parte \"KPE\" que nos comentó la profe y luego miro un KMeans para ver cómo quedan los grupos en las características HOG."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "hog_features = load_hog_features(dataset_df)\n\njoblib.dump({\n    'hog_features': hog_features,\n    'labels': dataset_df['label'].to_numpy(),\n    'paths': dataset_df['processed_path'].to_numpy()\n}, OUTPUT_DIR / 'hog_features.joblib')\n\nprint(f\"HOG guardado en {OUTPUT_DIR / 'hog_features.joblib'}\")\n\nkpca_viz = KernelPCA(n_components=2, kernel='rbf', gamma=0.03, random_state=42)\nhog_reduced = kpca_viz.fit_transform(hog_features)\n\nkmeans = KMeans(n_clusters=len(CATEGORIES), random_state=42, n_init='auto')\nclusters = kmeans.fit_predict(hog_features)\n\ncluster_counts = pd.Series(clusters).value_counts().sort_index()\nprint('Conteo por cluster:')\nprint(cluster_counts)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nscatter = axes[0].scatter(hog_reduced[:, 0], hog_reduced[:, 1], c=clusters, cmap='tab20', s=15)\naxes[0].set_title('Clusters sobre HOG reducidos (KPE)')\naxes[0].set_xlabel('Comp 1')\naxes[0].set_ylabel('Comp 2')\nlegend1 = axes[0].legend(*scatter.legend_elements(), title='Cluster', loc='best')\naxes[0].add_artist(legend1)\n\naxes[1].bar(cluster_counts.index, cluster_counts.values, color='teal')\naxes[1].set_xticks(cluster_counts.index)\naxes[1].set_xlabel('Cluster')\naxes[1].set_ylabel('Número de imágenes')\naxes[1].set_title('Cantidad de imágenes por cluster')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Pipeline con GridSearch y validación cruzada\nArmo el pipeline con: preprocesado → HOG → KernelPCA → escalado → SVM, hago el GridSearch con todo el dataset y validación cruzada y guardo el mejor modelo junto con los resultados."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "X = dataset_df['original_path'].to_numpy()\ny = dataset_df['label'].to_numpy()\n\npipeline = Pipeline([\n    ('hog', ImageToHog()),\n    ('kpca', KernelPCA(kernel='rbf', n_components=30, gamma=0.03, fit_inverse_transform=False, random_state=42)),\n    ('scaler', StandardScaler()),\n    ('clf', SVC(probability=False, random_state=42))\n])\n\nparam_grid = {\n    'hog__orientations': [8, 9],\n    'hog__pixels_per_cell': [(8, 8), (16, 16)],\n    'kpca__n_components': [20, 30, 40],\n    'kpca__gamma': [0.01, 0.03],\n    'clf__C': [1, 5, 10],\n    'clf__gamma': ['scale', 0.01]\n}\n\ngrid_search = GridSearchCV(\n    pipeline,\n    param_grid=param_grid,\n    cv=5,\n    scoring='accuracy',\n    n_jobs=-1,\n    verbose=2\n)\n\ngrid_search.fit(X, y)\n\nprint('Mejor score CV:', grid_search.best_score_)\nprint('Mejores parámetros:', grid_search.best_params_)\n\nbest_model = grid_search.best_estimator_\n\njoblib.dump(best_model, OUTPUT_DIR / 'animal_face_pipeline.joblib')\njoblib.dump(grid_search.cv_results_, OUTPUT_DIR / 'grid_search_results.joblib')\nprint(f\"Modelo guardado en {OUTPUT_DIR / 'animal_face_pipeline.joblib'}\")\nprint(f\"Resultados CV guardados en {OUTPUT_DIR / 'grid_search_results.joblib'}\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ny_pred = cross_val_predict(best_model, X, y, cv=cv_strategy, n_jobs=-1)\n\nprint(classification_report(y, y_pred))\n\ncm = confusion_matrix(y, y_pred, labels=best_model.classes_)\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\ndisp.plot(ax=ax, cmap='Blues', xticks_rotation=45, colorbar=False)\nplt.title('Matriz de confusión (validación cruzada)')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Cosas para mejorar luego\n- Probar con más parámetros del SVM o incluso otros clasificadores para comparar resultados.\n- Mirar si se puede reducir el tiempo de GridSearch ajustando mejor la búsqueda o usando menos componentes en KernelPCA.\n- Crear un pequeño dashboard para visualizar ejemplos mal clasificados según la validación cruzada."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}