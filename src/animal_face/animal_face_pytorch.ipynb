{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Reconocimiento de caras de animales con PyTorch\nEn este notebook replico el flujo del cuaderno original pero entrenando un clasificador basado en PyTorch. Mantengo el preprocesado cl\u00e1sico (grises a 64x64), genero un dataset listo para reutilizar y entreno una CNN sencilla para distinguir las especies.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Pasos previstos\n1. Reutilizar la rutina de preprocesado para dejar todas las im\u00e1genes en 64x64 escala de grises.\n2. Guardar/recuperar un descriptor intermedio para no recalcular todo cada vez.\n3. Construir `Dataset` y `DataLoader` de PyTorch con splits estratificados.\n4. Definir y entrenar una CNN ligera con monitorizaci\u00f3n de validaci\u00f3n.\n5. Evaluar en el split de test con m\u00e9tricas y matriz de confusi\u00f3n guardando el modelo entrenado.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport random\nimport json\n\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom PIL import Image, ImageOps, UnidentifiedImageError\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import StratifiedKFold\nfrom IPython.display import display\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\n\nplt.style.use('seaborn-v0_8')\nsns.set_theme()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "BASE_DIR = Path('.').resolve()\nDATA_DIR = BASE_DIR / 'AnimalFace' / 'Image'\nPROCESSED_DIR = BASE_DIR / 'AnimalFace' / 'processed_64_gray'\nOUTPUT_DIR = BASE_DIR / 'AnimalFace' / 'outputs'\nMODEL_DIR = OUTPUT_DIR / 'pytorch'\n\nIMAGE_SIZE = (64, 64)\nBATCH_SIZE = 64\n\nfor folder in (PROCESSED_DIR, OUTPUT_DIR, MODEL_DIR):\n    folder.mkdir(parents=True, exist_ok=True)\n\nif not DATA_DIR.exists():\n    raise FileNotFoundError(f'No encontr\u00e9 la carpeta de im\u00e1genes en {DATA_DIR}')\n\nCATEGORIES = sorted([p.name for p in DATA_DIR.iterdir() if p.is_dir()])\nprint(f'Trabajo con {len(CATEGORIES)} clases: {CATEGORIES}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Funciones de apoyo\nIgual que en el notebook base, centralizo la preparaci\u00f3n en helpers reutilizables.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from typing import List, Tuple\n\n\ndef collect_image_paths(class_name: str) -> List[Path]:\n    folder = DATA_DIR / class_name\n    supported = []\n    for pattern in ('*.jpg', '*.jpeg', '*.png', '*.bmp'):\n        supported.extend(folder.glob(pattern))\n    return sorted(supported)\n\n\ndef preprocess_image(path: Path, size: Tuple[int, int]) -> np.ndarray:\n    try:\n        with Image.open(path) as image:\n            image = ImageOps.exif_transpose(image)\n            image = ImageOps.grayscale(image)\n            image = image.resize(size, Image.Resampling.LANCZOS)\n            array = np.asarray(image, dtype=np.float32) / 255.0\n    except (UnidentifiedImageError, OSError) as exc:\n        raise ValueError(f'No pude cargar {path}') from exc\n    return array\n\n\ndef save_preprocessed_image(array: np.ndarray, original_path: Path) -> Path:\n    label = original_path.parent.name\n    save_dir = PROCESSED_DIR / label\n    save_dir.mkdir(parents=True, exist_ok=True)\n    save_path = save_dir / f\"{original_path.stem}_64_gray.png\"\n    image_to_save = Image.fromarray((array * 255).astype(np.uint8))\n    image_to_save.save(save_path)\n    return save_path\n\n\ndef build_dataset_descriptor() -> pd.DataFrame:\n    rows = []\n    skipped = 0\n    for label in CATEGORIES:\n        paths = collect_image_paths(label)\n        for path in paths:\n            try:\n                processed = preprocess_image(path, IMAGE_SIZE)\n            except ValueError:\n                print(f\"Salt\u00e9 {path.name} porque PIL no la reconoce bien.\")\n                skipped += 1\n                continue\n            saved_path = save_preprocessed_image(processed, path)\n            rows.append({\n                'label': label,\n                'original_path': path.as_posix(),\n                'processed_path': saved_path.as_posix()\n            })\n    df = pd.DataFrame(rows)\n    df = df.sort_values('label').reset_index(drop=True)\n    if skipped:\n        print(f\"Salt\u00e9 {skipped} im\u00e1genes que estaban da\u00f1adas o con formato raro.\")\n    return df\n\n\ndef show_before_after(df: pd.DataFrame, samples: int = 4) -> None:\n    subset = df.groupby('label').head(1)\n    subset = subset.sample(min(samples, len(subset)), random_state=42)\n    fig, axes = plt.subplots(len(subset), 2, figsize=(6, 3 * len(subset)))\n    if len(subset) == 1:\n        axes = np.array([[axes[0], axes[1]]])\n    for (_, row), ax_pair in zip(subset.iterrows(), axes):\n        with Image.open(row['original_path']) as original:\n            ax_pair[0].imshow(original)\n        with Image.open(row['processed_path']) as processed:\n            ax_pair[1].imshow(processed, cmap='gray')\n        ax_pair[0].set_title(f\"Original ({row['label']})\")\n        ax_pair[0].axis('off')\n        ax_pair[1].set_title('64x64 gris')\n        ax_pair[1].axis('off')\n    plt.tight_layout()\n    plt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Preparo (o cargo) el descriptor del dataset\nUso el mismo formato que antes pero guardo una copia independiente para PyTorch.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_path = OUTPUT_DIR / 'dataset_descriptor_pytorch.joblib'\n",
    "\n",
    "def rebuild_descriptor():\n",
    "    df = build_dataset_descriptor()\n",
    "    joblib.dump(df, descriptor_path)\n",
    "    print(f'Descriptor actualizado y guardado en {descriptor_path}')\n",
    "    return df\n",
    "\n",
    "def descriptor_is_outdated(df: pd.DataFrame) -> bool:\n",
    "    current_originals = {\n",
    "        path.as_posix()\n",
    "        for label in CATEGORIES\n",
    "        for path in collect_image_paths(label)\n",
    "    }\n",
    "    stored_originals = set(df['original_path'])\n",
    "    if current_originals != stored_originals:\n",
    "        missing = len(current_originals - stored_originals)\n",
    "        extra = len(stored_originals - current_originals)\n",
    "        if missing:\n",
    "            print(f'Hay {missing} im\u00e1genes nuevas sin describir.')\n",
    "        if extra:\n",
    "            print(f'Hay {extra} im\u00e1genes que ya no existen en la carpeta original.')\n",
    "        return True\n",
    "    missing_processed = [\n",
    "        row['processed_path']\n",
    "        for _, row in df.iterrows()\n",
    "        if not Path(row['processed_path']).exists()\n",
    "    ]\n",
    "    if missing_processed:\n",
    "        print(f'Faltan {len(missing_processed)} archivos preprocesados; regenero descriptor...')\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "if descriptor_path.exists():\n",
    "    dataset_df = joblib.load(descriptor_path)\n",
    "    stored_labels = set(dataset_df['label'].unique())\n",
    "    expected_labels = set(CATEGORIES)\n",
    "    needs_rebuild = stored_labels != expected_labels or descriptor_is_outdated(dataset_df)\n",
    "    if needs_rebuild:\n",
    "        print('El descriptor est\u00e1 desactualizado, lo vuelvo a generar...')\n",
    "        dataset_df = rebuild_descriptor()\n",
    "    else:\n",
    "        print(f'Descriptor cargado de {descriptor_path}')\n",
    "else:\n",
    "    dataset_df = rebuild_descriptor()\n",
    "\n",
    "print(dataset_df.head())\n",
    "print()\n",
    "print(dataset_df['label'].value_counts())\n",
    "\n",
    "show_before_after(dataset_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Dataset y DataLoaders\nAhora convierto el descriptor en splits estratificados y DataLoaders listos para PyTorch.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "label_to_idx = {label: idx for idx, label in enumerate(CATEGORIES)}\nidx_to_label = {idx: label for label, idx in label_to_idx.items()}\n\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\nclass AnimalFaceDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, label_to_idx: dict, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.label_to_idx = label_to_idx\n\n    def __len__(self) -> int:\n        return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        path = Path(row['processed_path'])\n        with Image.open(path) as image:\n            image = ImageOps.exif_transpose(image)\n            if self.transform is not None:\n                tensor = self.transform(image)\n            else:\n                tensor = transforms.ToTensor()(image)\n        label_idx = self.label_to_idx[row['label']]\n        return tensor, label_idx\n\ndef build_loader(df: pd.DataFrame, shuffle: bool):\n    dataset = AnimalFaceDataset(df, label_to_idx, transform=transform)\n    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=0)\n    return dataset, loader\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Defino la CNN\nModelo compacto con tres bloques conv-bn-relu y un clasificador totalmente conectado.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "FEATURE_DIM = 128 * (IMAGE_SIZE[0] // 8) * (IMAGE_SIZE[1] // 8)\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes: int):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(FEATURE_DIM, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnum_classes = len(CATEGORIES)\nprint(f'Entrenar\u00e9 en: {device}')\n\ndef create_model():\n    return SimpleCNN(num_classes=num_classes).to(device)\n\ndef create_criterion():\n    return nn.CrossEntropyLoss()\n\ndef create_optimizer(model):\n    return torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\ndef create_scheduler(optimizer):\n    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5, verbose=True)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Entrenamiento\nCiclo cl\u00e1sico con early stopping cuando la validaci\u00f3n deja de mejorar.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_epoch(dataloader, model, criterion, optimizer=None):\n    is_train = optimizer is not None\n    model.train() if is_train else model.eval()\n    epoch_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, targets in dataloader:\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n\n        if is_train:\n            optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n        if is_train:\n            loss.backward()\n            optimizer.step()\n\n        epoch_loss += loss.item() * inputs.size(0)\n        preds = outputs.argmax(dim=1)\n        correct += (preds == targets).sum().item()\n        total += targets.size(0)\n\n    avg_loss = epoch_loss / total\n    accuracy = correct / total\n    return avg_loss, accuracy\n\nEPOCHS = 30\nPATIENCE = 5\n\ndef train_model(train_loader, val_loader, fold_id=None):\n    model = create_model()\n    criterion = create_criterion()\n    optimizer = create_optimizer(model)\n    scheduler = create_scheduler(optimizer)\n\n    history = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': []\n    }\n\n    best_val_acc = 0.0\n    patience_counter = 0\n    best_state_dict = None\n\n    for epoch in range(1, EPOCHS + 1):\n        train_loss, train_acc = run_epoch(train_loader, model, criterion, optimizer)\n        val_loss, val_acc = run_epoch(val_loader, model, criterion)\n\n        scheduler.step(val_acc)\n\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n\n        prefix = f\"Fold {fold_id} \" if fold_id is not None else \"\"\n        print(f\"{prefix}Epoch {epoch:02d} | train_loss={train_loss:.4f} acc={train_acc:.4f} | val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_state_dict = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n            patience_counter = 0\n            print('  \u21b3 nuevo mejor modelo')\n        else:\n            patience_counter += 1\n\n        if patience_counter >= PATIENCE:\n            print('Early stopping activado.')\n            break\n\n    if best_state_dict is None:\n        best_state_dict = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n    model.load_state_dict(best_state_dict)\n    return model, history, best_state_dict, best_val_acc\n\n\ndef collect_predictions(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_targets = []\n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n            outputs = model(inputs)\n            preds = outputs.argmax(dim=1)\n            all_preds.append(preds.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n    y_pred = np.concatenate(all_preds)\n    y_true = np.concatenate(all_targets)\n    return y_true, y_pred\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "N_SPLITS = 5\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n\nfold_histories = []\nfold_metrics = []\noof_true = []\noof_pred = []\n\nbest_fold = {\n    'val_acc': float('-inf'),\n    'fold': None,\n    'state_dict': None,\n    'val_df': None,\n    'dataset': None,\n    'history': None,\n    'state_path': None\n}\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(dataset_df, dataset_df['label']), start=1):\n    print(f\"===== Fold {fold}/{N_SPLITS} =====\")\n    train_df = dataset_df.iloc[train_idx]\n    val_df = dataset_df.iloc[val_idx]\n\n    _, train_loader = build_loader(train_df, shuffle=True)\n    val_dataset, val_loader = build_loader(val_df, shuffle=False)\n\n    model, history, best_state_dict, best_val_acc = train_model(train_loader, val_loader, fold_id=fold)\n\n    fold_histories.append(history)\n    fold_metrics.append({\n        'fold': fold,\n        'train_size': len(train_df),\n        'val_size': len(val_df),\n        'best_val_acc': best_val_acc,\n        'epochs_ran': len(history['train_loss'])\n    })\n\n    torch.save(best_state_dict, MODEL_DIR / f'animal_face_cnn_fold{fold}.pt')\n\n    y_true, y_pred = collect_predictions(model, val_loader)\n    oof_true.extend(y_true.tolist())\n    oof_pred.extend(y_pred.tolist())\n\n    with open(MODEL_DIR / f'training_history_fold{fold}.json', 'w') as fp:\n        json.dump(history, fp, indent=2)\n\n    if best_val_acc >= best_fold['val_acc']:\n        best_fold = {\n            'val_acc': best_val_acc,\n            'fold': fold,\n            'state_dict': best_state_dict,\n            'val_df': val_df.reset_index(drop=True),\n            'dataset': val_dataset,\n            'history': {k: v[:] for k, v in history.items()},\n            'state_path': MODEL_DIR / 'animal_face_cnn_best.pt'\n        }\n        torch.save(best_state_dict, MODEL_DIR / 'animal_face_cnn_best.pt')\n\nfold_metrics_df = pd.DataFrame(fold_metrics)\ndisplay(fold_metrics_df)\n\nprint(\"\\nAccuracy promedio (OOF):\", (np.array(oof_true) == np.array(oof_pred)).mean())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Curvas de entrenamiento\nVisualizo las m\u00e9tricas registradas para verificar el aprendizaje.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "best_history = best_fold['history']\nif best_history is None:\n    raise RuntimeError('Ejecuta la celda de validaci\u00f3n cruzada antes de graficar.')\n\nepochs_ran = len(best_history['train_loss'])\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nepoch_range = range(1, epochs_ran + 1)\naxes[0].plot(epoch_range, best_history['train_loss'], label='Train')\naxes[0].plot(epoch_range, best_history['val_loss'], label='Val')\naxes[0].set_title(f'Fold {best_fold[\"fold\"]} - Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].legend()\n\naxes[1].plot(epoch_range, best_history['train_acc'], label='Train')\naxes[1].plot(epoch_range, best_history['val_acc'], label='Val')\naxes[1].set_title(f'Fold {best_fold[\"fold\"]} - Accuracy')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Evaluaci\u00f3n con validaci\u00f3n cruzada\nCalculo m\u00e9tricas y la matriz de confusi\u00f3n usando las predicciones out-of-fold.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not oof_true:\n    raise RuntimeError('Ejecuta antes la celda de validaci\u00f3n cruzada para obtener predicciones OOF.')\n\noof_true_arr = np.array(oof_true, dtype=int)\noof_pred_arr = np.array(oof_pred, dtype=int)\nlabels_idx = list(range(len(CATEGORIES)))\n\nprint(classification_report(oof_true_arr, oof_pred_arr, labels=labels_idx, target_names=CATEGORIES))\n\ncm = confusion_matrix(oof_true_arr, oof_pred_arr, labels=labels_idx)\nnum_classes = len(CATEGORIES)\nfig_size = max(8, num_classes * 0.6)\nfig, ax = plt.subplots(figsize=(fig_size, fig_size))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CATEGORIES)\ndisp.plot(ax=ax, cmap='Blues', colorbar=False)\nrotation = 90 if num_classes > 10 else 45\ndisp.ax_.set_xticklabels(CATEGORIES, rotation=rotation, ha='right')\ndisp.ax_.set_yticklabels(CATEGORIES)\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ejemplos de predicciones\nMuestro algunas im\u00e1genes del fold con mejor validaci\u00f3n (usar tras la validaci\u00f3n cruzada).\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def show_predictions(model, dataset: Dataset, num_samples: int = 6):\n    model.eval()\n    indices = np.random.choice(len(dataset), size=min(num_samples, len(dataset)), replace=False)\n    cols = min(3, len(indices))\n    rows = int(np.ceil(len(indices) / cols))\n    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n    axes = np.array(axes).reshape(-1)\n\n    for ax, idx in zip(axes, indices):\n        image_tensor, label_idx = dataset[idx]\n        image = image_tensor.clone().detach()\n        image = image * 0.5 + 0.5\n        image_np = image.squeeze().numpy()\n\n        with torch.no_grad():\n            output = model(image_tensor.unsqueeze(0).to(device))\n            pred_idx = output.argmax(dim=1).item()\n\n        ax.imshow(image_np, cmap='gray')\n        ax.set_title(f\"Real: {idx_to_label[label_idx]}\\nPred: {idx_to_label[pred_idx]}\")\n        ax.axis('off')\n\n    for ax in axes[len(indices):]:\n        ax.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\nif best_fold['state_dict'] is None or best_fold['dataset'] is None:\n    raise RuntimeError('Ejecuta antes la celda de validaci\u00f3n cruzada para obtener un modelo entrenado.')\n\nbest_model_for_display = create_model()\nbest_model_for_display.load_state_dict(best_fold['state_dict'])\nshow_predictions(best_model_for_display, best_fold['dataset'])\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ideas para pr\u00f3ximas iteraciones\n- Ajustar hiperpar\u00e1metros (capas, regularizaci\u00f3n o learning rate schedule).\n- Probar data augmentation antes del `Normalize` para robustecer el modelo.\n- Implementar m\u00e9tricas adicionales (f1 macro/micro) y tensorboard para monitorizar.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}